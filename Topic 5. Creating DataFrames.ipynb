{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbaa6272",
   "metadata": {},
   "source": [
    "### Creating Pandas DataFrame\n",
    "\n",
    "#### Using DataFrame constructor pd.DataFrame()\n",
    "\n",
    "The pandas DataFrame() constructor offers many different ways to create and initialize a dataframe.\n",
    "\n",
    "#### Method 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4d9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe75e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "(0, 0)\n",
      "Empty DataFrame\n",
      "Columns: [Name, Age, Address]\n",
      "Index: []\n",
      "   Name  Age Address\n",
      "0  Anil   23   Delhi\n",
      "1   Ram   34  EDelhi\n"
     ]
    }
   ],
   "source": [
    "# method 0\n",
    "# Initialize a blank dataframe \n",
    "\n",
    "df = pd.DataFrame()\n",
    "print(df)\n",
    "print(df.shape)\n",
    "\n",
    "# Initialize a blank dataframe with coulmn names and keep adding\n",
    "\n",
    "df1 = pd.DataFrame(columns=['Name','Age','Address'])\n",
    "print(df1)\n",
    "\n",
    "# Add records to dataframe using the .loc function\n",
    "df1.loc[0] = ['Anil',23,'Delhi']\n",
    "df1.loc[1] = ['Ram',34, 'EDelhi']\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe94c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age Address\n",
      "0    Anil   23   Delhi\n",
      "1     Ram   34  EDelhi\n",
      "3  Himani   23     FBD\n"
     ]
    }
   ],
   "source": [
    "# Add records to dataframe using the .loc function\n",
    "df1.loc[0] = ['Anil',23,'Delhi']\n",
    "df1.loc[1] = ['Ram',34, 'EDelhi']\n",
    "df1.loc[3] = ['Himani',23,'FBD']\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ceeb82",
   "metadata": {},
   "source": [
    "#### Method 1:\n",
    "Using numpy array in the DataFrame constructor. Pass a 2D numpy array — each array is the corresponding row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d788b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>INR</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>Dollar</td>\n",
       "      <td>Eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>Pound</td>\n",
       "      <td>Eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Currency Language\n",
       "0   India      INR    Hindi\n",
       "1     USA   Dollar      Eng\n",
       "2      UK    Pound      Eng"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass a 2D numpy array - each row is the corresponding row required in the dataframe\n",
    "\n",
    "data = np.array([['India','INR','Hindi'],\n",
    "                 ['USA','Dollar','Eng'],\n",
    "                ['UK','Pound','Eng']])\n",
    "\n",
    "# pass column names in the columns parameter \n",
    "\n",
    "df2 = pd.DataFrame(data, columns=['Country','Currency','Language'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2c571",
   "metadata": {},
   "source": [
    "#### Method 2:\n",
    "\n",
    "Using dictionary in the DataFrame constructor. Dictionary Keys become Column names in the dataframe. Dictionary values become the values of columns. Column values are combined in a single row according to the order in which they are specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb884244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>toyota</td>\n",
       "      <td>corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>honda</td>\n",
       "      <td>civic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>hyndai</td>\n",
       "      <td>accent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>nissan</td>\n",
       "      <td>sentra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    make    model\n",
       "0  2014  toyota  corolla\n",
       "1  2018   honda    civic\n",
       "2  2020  hyndai   accent\n",
       "3  2017  nissan   sentra"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary\n",
    "\n",
    "data = {'year': [2014, 2018,2020,2017], \n",
    "        'make': [\"toyota\", \"honda\",\"hyndai\",\"nissan\"],\n",
    "        'model':[\"corolla\", \"civic\",\"accent\",\"sentra\"]\n",
    "       }\n",
    "\n",
    "# Creating a dataframe using above dictionary\n",
    "df3 = pd.DataFrame(data)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3111ea3",
   "metadata": {},
   "source": [
    "#### Method 3:\n",
    "\n",
    "Using a list of dictionaries in the DataFrame constructor. Each dictionary is a record. Dictionary Keys become Column names in the dataframe. Dictionary values become the values of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1974b6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>toyota</td>\n",
       "      <td>corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>honda</td>\n",
       "      <td>civic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>hyndai</td>\n",
       "      <td>nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>nissan</td>\n",
       "      <td>sentra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    make    model\n",
       "0  2014  toyota  corolla\n",
       "1  2018   honda    civic\n",
       "2  2020  hyndai   nissan\n",
       "3  2017  nissan   sentra"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{'year': 2014, 'make': \"toyota\", 'model':\"corolla\"}, \n",
    "        {'year': 2018, 'make': \"honda\", 'model':\"civic\"}, \n",
    "        {'year': 2020, 'make': \"hyndai\", 'model':\"nissan\"}, \n",
    "        {'year': 2017, 'make': \"nissan\" ,'model':\"sentra\"}\n",
    "       ]\n",
    "\n",
    "# pass column names in the columns parameter \n",
    "df4 = pd.DataFrame(data)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db598f",
   "metadata": {},
   "source": [
    "#### Method 4:\n",
    "\n",
    "Using dictionary in the from_dict method. Dictionary Keys become Column names in the dataframe. Dictionary values become the vaues of columns. Column values are combined in a single row according to the order in which they are specified. ```pd.DataFrame.from_dict(data)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb27ad80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>toyota</td>\n",
       "      <td>corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>honda</td>\n",
       "      <td>civic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>hyndai</td>\n",
       "      <td>accent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>nissan</td>\n",
       "      <td>sentra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    make    model\n",
       "0  2014  toyota  corolla\n",
       "1  2018   honda    civic\n",
       "2  2020  hyndai   accent\n",
       "3  2017  nissan   sentra"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'year': [2014, 2018,2020,2017], \n",
    "        'make': [\"toyota\", \"honda\",\"hyndai\",\"nissan\"],\n",
    "        'model':[\"corolla\", \"civic\",\"accent\",\"sentra\"]\n",
    "       }\n",
    "\n",
    "# pass column names in the columns parameter \n",
    "# using pd.DataFrame.from_dict(...)\n",
    "\n",
    "df5 = pd.DataFrame.from_dict(data)\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa8167",
   "metadata": {},
   "source": [
    "### Using pandas library functions — read_csv\n",
    "\n",
    "#### Method 5:\n",
    "\n",
    "From a csv file using read_csv method of pandas library. This is one of the most common ways of dataframe creation for EDA. Delimiter (or separator) , header and the choice of index column from the csv file is configurable. By default, separator is comma, header is inferred from first line if found, index column is not taken from the file. Here is how the file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e66b654e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>personName</th>\n",
       "      <th>age</th>\n",
       "      <th>finalWorth</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>organization</th>\n",
       "      <th>selfMade</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>title</th>\n",
       "      <th>philanthropyScore</th>\n",
       "      <th>residenceMsa</th>\n",
       "      <th>numberOfSiblings</th>\n",
       "      <th>bio</th>\n",
       "      <th>about</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>50.0</td>\n",
       "      <td>219000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>United States</td>\n",
       "      <td>Texas</td>\n",
       "      <td>...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1971-06-28</td>\n",
       "      <td>CEO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elon Musk is working to revolutionize transpor...</td>\n",
       "      <td>Musk was accepted to a graduate program at Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>58.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>United States</td>\n",
       "      <td>Washington</td>\n",
       "      <td>...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1964-01-12</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Seattle-Tacoma-Bellevue, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeff Bezos founded e-commerce giant Amazon in ...</td>\n",
       "      <td>Growing up, Jeff Bezos worked summers on his g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>73.0</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>LVMH Moët Hennessy Louis Vuitton</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>1949-03-05</td>\n",
       "      <td>Chairman and CEO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bernard Arnault oversees the LVMH empire of so...</td>\n",
       "      <td>Arnault apparently wooed his wife, Helene Merc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>66.0</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>United States</td>\n",
       "      <td>Washington</td>\n",
       "      <td>...</td>\n",
       "      <td>Bill &amp; Melinda Gates Foundation</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1955-10-28</td>\n",
       "      <td>Cofounder</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Seattle-Tacoma-Bellevue, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bill Gates turned his fortune from software fi...</td>\n",
       "      <td>When Gates was a kid, he spent so much time re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>91.0</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>United States</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>...</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1930-08-30</td>\n",
       "      <td>CEO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Omaha, NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Known as the \"Oracle of Omaha,\" Warren Buffett...</td>\n",
       "      <td>Buffett still lives in the same Omaha, Nebrask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>2578</td>\n",
       "      <td>Zhang Yuqiang</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Fiberglass</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1955-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhang Yuqiang chairs Zhenshi Holding Group, a ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>2578</td>\n",
       "      <td>Zhou Ruxin</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Navigation</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1963-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhou Ruxin chairs Beijing BDStar Navigation, a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>2578</td>\n",
       "      <td>Wen Zhou &amp; family</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>chemicals</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1965-03-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhou Wen chairs Shanghai Pret Composites, a su...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>2578</td>\n",
       "      <td>Zhou Yifeng &amp; family</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Energy</td>\n",
       "      <td>liquefied petroleum gas</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>1978-07-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhou Yifeng chairs Shenzhen-listed Oriental En...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>2578</td>\n",
       "      <td>Zhuang Kuilong &amp; family</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>polyester</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "      <td>1962-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhuang Kuilong chairs Xinfengming Group, a man...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2668 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank                personName   age  finalWorth  year  month  \\\n",
       "0        1                 Elon Musk  50.0    219000.0  2022      4   \n",
       "1        2                Jeff Bezos  58.0    171000.0  2022      4   \n",
       "2        3  Bernard Arnault & family  73.0    158000.0  2022      4   \n",
       "3        4                Bill Gates  66.0    129000.0  2022      4   \n",
       "4        5            Warren Buffett  91.0    118000.0  2022      4   \n",
       "...    ...                       ...   ...         ...   ...    ...   \n",
       "2663  2578             Zhang Yuqiang  66.0      1000.0  2022      4   \n",
       "2664  2578                Zhou Ruxin  59.0      1000.0  2022      4   \n",
       "2665  2578         Wen Zhou & family  57.0      1000.0  2022      4   \n",
       "2666  2578      Zhou Yifeng & family  43.0      1000.0  2022      4   \n",
       "2667  2578   Zhuang Kuilong & family  59.0      1000.0  2022      4   \n",
       "\n",
       "                   category                   source        country  \\\n",
       "0                Automotive            Tesla, SpaceX  United States   \n",
       "1                Technology                   Amazon  United States   \n",
       "2          Fashion & Retail                     LVMH         France   \n",
       "3                Technology                Microsoft  United States   \n",
       "4     Finance & Investments       Berkshire Hathaway  United States   \n",
       "...                     ...                      ...            ...   \n",
       "2663          Manufacturing               Fiberglass          China   \n",
       "2664             Technology               Navigation          China   \n",
       "2665          Manufacturing                chemicals          China   \n",
       "2666                 Energy  liquefied petroleum gas          China   \n",
       "2667          Manufacturing                polyester          China   \n",
       "\n",
       "           state  ...                      organization selfMade gender  \\\n",
       "0          Texas  ...                             Tesla     True      M   \n",
       "1     Washington  ...                            Amazon     True      M   \n",
       "2            NaN  ...  LVMH Moët Hennessy Louis Vuitton    False      M   \n",
       "3     Washington  ...   Bill & Melinda Gates Foundation     True      M   \n",
       "4       Nebraska  ...                Berkshire Hathaway     True      M   \n",
       "...          ...  ...                               ...      ...    ...   \n",
       "2663         NaN  ...                               NaN     True      M   \n",
       "2664         NaN  ...                               NaN     True      M   \n",
       "2665         NaN  ...                               NaN     True      M   \n",
       "2666         NaN  ...                               NaN     True      F   \n",
       "2667         NaN  ...                               NaN     True      M   \n",
       "\n",
       "       birthDate             title philanthropyScore  \\\n",
       "0     1971-06-28               CEO               1.0   \n",
       "1     1964-01-12      Entrepreneur               1.0   \n",
       "2     1949-03-05  Chairman and CEO               NaN   \n",
       "3     1955-10-28         Cofounder               4.0   \n",
       "4     1930-08-30               CEO               5.0   \n",
       "...          ...               ...               ...   \n",
       "2663  1955-09-01               NaN               NaN   \n",
       "2664  1963-03-01               NaN               NaN   \n",
       "2665  1965-03-06               NaN               NaN   \n",
       "2666  1978-07-11               NaN               NaN   \n",
       "2667  1962-06-15               NaN               NaN   \n",
       "\n",
       "                     residenceMsa  numberOfSiblings  \\\n",
       "0                             NaN               NaN   \n",
       "1     Seattle-Tacoma-Bellevue, WA               NaN   \n",
       "2                             NaN               NaN   \n",
       "3     Seattle-Tacoma-Bellevue, WA               NaN   \n",
       "4                       Omaha, NE               NaN   \n",
       "...                           ...               ...   \n",
       "2663                          NaN               NaN   \n",
       "2664                          NaN               NaN   \n",
       "2665                          NaN               NaN   \n",
       "2666                          NaN               NaN   \n",
       "2667                          NaN               NaN   \n",
       "\n",
       "                                                    bio  \\\n",
       "0     Elon Musk is working to revolutionize transpor...   \n",
       "1     Jeff Bezos founded e-commerce giant Amazon in ...   \n",
       "2     Bernard Arnault oversees the LVMH empire of so...   \n",
       "3     Bill Gates turned his fortune from software fi...   \n",
       "4     Known as the \"Oracle of Omaha,\" Warren Buffett...   \n",
       "...                                                 ...   \n",
       "2663  Zhang Yuqiang chairs Zhenshi Holding Group, a ...   \n",
       "2664  Zhou Ruxin chairs Beijing BDStar Navigation, a...   \n",
       "2665  Zhou Wen chairs Shanghai Pret Composites, a su...   \n",
       "2666  Zhou Yifeng chairs Shenzhen-listed Oriental En...   \n",
       "2667  Zhuang Kuilong chairs Xinfengming Group, a man...   \n",
       "\n",
       "                                                  about  \n",
       "0     Musk was accepted to a graduate program at Sta...  \n",
       "1     Growing up, Jeff Bezos worked summers on his g...  \n",
       "2     Arnault apparently wooed his wife, Helene Merc...  \n",
       "3     When Gates was a kid, he spent so much time re...  \n",
       "4     Buffett still lives in the same Omaha, Nebrask...  \n",
       "...                                                 ...  \n",
       "2663                                                NaN  \n",
       "2664                                                NaN  \n",
       "2665                                                NaN  \n",
       "2666                                                NaN  \n",
       "2667                                                NaN  \n",
       "\n",
       "[2668 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"DataSets/forbes_2022_billionaires.csv\", )\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1b979",
   "metadata": {},
   "source": [
    "### Using pandas library functions — read_excel\n",
    "\n",
    "#### Method 6:\n",
    "From an excel file using read_csv method of pandas library. This is one of the most common ways of dataframe creation for EDA. Delimiter (or separator) , header and the choice of index column from the excel file is configurable. By default, separator is comma, header is inferred from first line if found, index column is not taken from the file. Here is how the file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8978033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>9990</td>\n",
       "      <td>CA-2014-110422</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>TB-21400</td>\n",
       "      <td>Tom Boeckenhauer</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Miami</td>\n",
       "      <td>...</td>\n",
       "      <td>33180</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-FU-10001889</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Ultra Door Pull Handle</td>\n",
       "      <td>25.2480</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>9991</td>\n",
       "      <td>CA-2017-121258</td>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>DB-13060</td>\n",
       "      <td>Dave Brooks</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Costa Mesa</td>\n",
       "      <td>...</td>\n",
       "      <td>92627</td>\n",
       "      <td>West</td>\n",
       "      <td>FUR-FU-10000747</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Tenex B1-RE Series Chair Mats for Low Pile Car...</td>\n",
       "      <td>91.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.6332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>9992</td>\n",
       "      <td>CA-2017-121258</td>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>DB-13060</td>\n",
       "      <td>Dave Brooks</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Costa Mesa</td>\n",
       "      <td>...</td>\n",
       "      <td>92627</td>\n",
       "      <td>West</td>\n",
       "      <td>TEC-PH-10003645</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Aastra 57i VoIP phone</td>\n",
       "      <td>258.5760</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.3932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>9993</td>\n",
       "      <td>CA-2017-121258</td>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>DB-13060</td>\n",
       "      <td>Dave Brooks</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Costa Mesa</td>\n",
       "      <td>...</td>\n",
       "      <td>92627</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-PA-10004041</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Paper</td>\n",
       "      <td>It's Hot Message Books with Stickers, 2 3/4\" x 5\"</td>\n",
       "      <td>29.6000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>9994</td>\n",
       "      <td>CA-2017-119914</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CC-12220</td>\n",
       "      <td>Chris Cortes</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>...</td>\n",
       "      <td>92683</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-AP-10002684</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Acco 7-Outlet Masterpiece Power Center, Wihtou...</td>\n",
       "      <td>243.1600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.9480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9994 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
       "0          1  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
       "1          2  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
       "2          3  CA-2016-138688 2016-06-12 2016-06-16    Second Class   \n",
       "3          4  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
       "4          5  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
       "...      ...             ...        ...        ...             ...   \n",
       "9989    9990  CA-2014-110422 2014-01-21 2014-01-23    Second Class   \n",
       "9990    9991  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
       "9991    9992  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
       "9992    9993  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
       "9993    9994  CA-2017-119914 2017-05-04 2017-05-09    Second Class   \n",
       "\n",
       "     Customer ID     Customer Name    Segment        Country             City  \\\n",
       "0       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
       "1       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
       "2       DV-13045   Darrin Van Huff  Corporate  United States      Los Angeles   \n",
       "3       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       "4       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       "...          ...               ...        ...            ...              ...   \n",
       "9989    TB-21400  Tom Boeckenhauer   Consumer  United States            Miami   \n",
       "9990    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
       "9991    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
       "9992    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
       "9993    CC-12220      Chris Cortes   Consumer  United States      Westminster   \n",
       "\n",
       "      ... Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0     ...       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1     ...       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2     ...       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3     ...       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4     ...       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "...   ...         ...     ...              ...              ...          ...   \n",
       "9989  ...       33180   South  FUR-FU-10001889        Furniture  Furnishings   \n",
       "9990  ...       92627    West  FUR-FU-10000747        Furniture  Furnishings   \n",
       "9991  ...       92627    West  TEC-PH-10003645       Technology       Phones   \n",
       "9992  ...       92627    West  OFF-PA-10004041  Office Supplies        Paper   \n",
       "9993  ...       92683    West  OFF-AP-10002684  Office Supplies   Appliances   \n",
       "\n",
       "                                           Product Name     Sales  Quantity  \\\n",
       "0                     Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1     Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2     Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3         Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                        Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "...                                                 ...       ...       ...   \n",
       "9989                             Ultra Door Pull Handle   25.2480         3   \n",
       "9990  Tenex B1-RE Series Chair Mats for Low Pile Car...   91.9600         2   \n",
       "9991                              Aastra 57i VoIP phone  258.5760         2   \n",
       "9992  It's Hot Message Books with Stickers, 2 3/4\" x 5\"   29.6000         4   \n",
       "9993  Acco 7-Outlet Masterpiece Power Center, Wihtou...  243.1600         2   \n",
       "\n",
       "      Discount    Profit  \n",
       "0         0.00   41.9136  \n",
       "1         0.00  219.5820  \n",
       "2         0.00    6.8714  \n",
       "3         0.45 -383.0310  \n",
       "4         0.20    2.5164  \n",
       "...        ...       ...  \n",
       "9989      0.20    4.1028  \n",
       "9990      0.00   15.6332  \n",
       "9991      0.20   19.3932  \n",
       "9992      0.00   13.3200  \n",
       "9993      0.00   72.9480  \n",
       "\n",
       "[9994 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.read_excel('~\\Superstore.xls')\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa2f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:       Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
       " 0          1  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
       " 1          2  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
       " 2          3  CA-2016-138688 2016-06-12 2016-06-16    Second Class   \n",
       " 3          4  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
       " 4          5  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
       " ...      ...             ...        ...        ...             ...   \n",
       " 9989    9990  CA-2014-110422 2014-01-21 2014-01-23    Second Class   \n",
       " 9990    9991  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
       " 9991    9992  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
       " 9992    9993  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
       " 9993    9994  CA-2017-119914 2017-05-04 2017-05-09    Second Class   \n",
       " \n",
       "      Customer ID     Customer Name    Segment        Country             City  \\\n",
       " 0       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
       " 1       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
       " 2       DV-13045   Darrin Van Huff  Corporate  United States      Los Angeles   \n",
       " 3       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       " 4       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       " ...          ...               ...        ...            ...              ...   \n",
       " 9989    TB-21400  Tom Boeckenhauer   Consumer  United States            Miami   \n",
       " 9990    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
       " 9991    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
       " 9992    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
       " 9993    CC-12220      Chris Cortes   Consumer  United States      Westminster   \n",
       " \n",
       "       ... Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       " 0     ...       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       " 1     ...       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       " 2     ...       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       " 3     ...       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       " 4     ...       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       " ...   ...         ...     ...              ...              ...          ...   \n",
       " 9989  ...       33180   South  FUR-FU-10001889        Furniture  Furnishings   \n",
       " 9990  ...       92627    West  FUR-FU-10000747        Furniture  Furnishings   \n",
       " 9991  ...       92627    West  TEC-PH-10003645       Technology       Phones   \n",
       " 9992  ...       92627    West  OFF-PA-10004041  Office Supplies        Paper   \n",
       " 9993  ...       92683    West  OFF-AP-10002684  Office Supplies   Appliances   \n",
       " \n",
       "                                            Product Name     Sales  Quantity  \\\n",
       " 0                     Bush Somerset Collection Bookcase  261.9600         2   \n",
       " 1     Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       " 2     Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       " 3         Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       " 4                        Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       " ...                                                 ...       ...       ...   \n",
       " 9989                             Ultra Door Pull Handle   25.2480         3   \n",
       " 9990  Tenex B1-RE Series Chair Mats for Low Pile Car...   91.9600         2   \n",
       " 9991                              Aastra 57i VoIP phone  258.5760         2   \n",
       " 9992  It's Hot Message Books with Stickers, 2 3/4\" x 5\"   29.6000         4   \n",
       " 9993  Acco 7-Outlet Masterpiece Power Center, Wihtou...  243.1600         2   \n",
       " \n",
       "       Discount    Profit  \n",
       " 0         0.00   41.9136  \n",
       " 1         0.00  219.5820  \n",
       " 2         0.00    6.8714  \n",
       " 3         0.45 -383.0310  \n",
       " 4         0.20    2.5164  \n",
       " ...        ...       ...  \n",
       " 9989      0.20    4.1028  \n",
       " 9990      0.00   15.6332  \n",
       " 9991      0.20   19.3932  \n",
       " 9992      0.00   13.3200  \n",
       " 9993      0.00   72.9480  \n",
       " \n",
       " [9994 rows x 21 columns],\n",
       " 2:               Person   Region\n",
       " 0      Anna Andreadi     West\n",
       " 1        Chuck Magee     East\n",
       " 2     Kelly Williams  Central\n",
       " 3  Cassandra Brandow    South}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.read_excel('~\\Superstore.xls', sheet_name=[0,2])\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371decb0",
   "metadata": {},
   "source": [
    "### Using pandas library functions — read_json\n",
    "\n",
    "#### Method 7:\n",
    "\n",
    "From a json file using read_json method of pandas library when the json file has a record in each line. Setting lines=True mean Read the file as a json object per line. Here is how the json file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce55550",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a json file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdf7\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuperstore.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Reading a json file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df8 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuperstore.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "# Creating a json file\n",
    "\n",
    "df7.to_json('superstore.json')\n",
    "\n",
    "# Reading a json file\n",
    "\n",
    "df8 = pd.read_json('superstore.json')\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c49a19c",
   "metadata": {},
   "source": [
    "#### Method 8:\n",
    "\n",
    "From a string of csv records using read_csv method of pandas library. This is particularly useful when we dont want to create a file but we have record structures handy- all we do is convert a csv record “string” to a file handle using StringIO library function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f741f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# f is a file handle created from a csv like string\n",
    "# StringIO(string)\n",
    "\n",
    "f= 'year,make,model\\n2014,toyota,corolla\\n2018,honda,civic\\n2020,hyndai,accent\\n2017,nissan,sentra'\n",
    "f = io.StringIO(f)\n",
    "df9 = pd.read_csv(f)\n",
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef908c82",
   "metadata": {},
   "source": [
    "#### Method 9:\n",
    "\n",
    "From a string of json records using read_json method of pandas library. This is particularly useful when we dont want to create a file but we have json record structures handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fabd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "# Home Work\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baefa913",
   "metadata": {},
   "source": [
    "#### Method 10:\n",
    "\n",
    "One of the most interesting ones — read tables from an HTML page using the pandas library built in read_html. This generates a list of dataframes; behind the scenes it scrapes the html page for any <table> tags and tries to capture the table into a dataframe. Even if there is only one table in the page, a list of dataframes is created — so it needs to be accessed using list subscript. The example below shows how to capture an HTML page and then load the tables — this uses the requests library to get the HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13839473",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,pandas\n",
    "url = 'https://www.goodcarbadcar.net/2020-us-vehicle-sales-figures-by-brand'\n",
    "r = requests.get(url)\n",
    "\n",
    "#if the response status is OK (200)\n",
    "if r.status_code == 200:\n",
    "    # from the response object, pass the response text \n",
    "    # to read_html and get list of tables as list of dataframes\n",
    "    \n",
    "     car_data_tables = pandas.read_html(r.text)\n",
    "\n",
    "# display the first table\n",
    "car_data_tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3f7b65f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found matching pattern '.+'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(r.text)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# if the response status is OK (200)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     # from the response object, pass the response text \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     # to read_html and get list of tables as list of dataframes\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m      car_data_tables \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# # display the first table\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(car_data_tables)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:1113\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1109\u001b[0m validate_header_arg(header)\n\u001b[0;32m   1111\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:939\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m--> 939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[0;32m    941\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:919\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 919\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:239\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:585\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[1;34m(self, doc, match, attrs)\u001b[0m\n\u001b[0;32m    582\u001b[0m     unique_tables\u001b[38;5;241m.\u001b[39madd(table)\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found matching pattern \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(match\u001b[38;5;241m.\u001b[39mpattern)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found matching pattern '.+'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'https://www.goodcarbadcar.net/2020-us-vehicle-sales-figures-by-brand/'\n",
    "r = requests.get(url)\n",
    "# print(r.text)\n",
    "# if the response status is OK (200)\n",
    "if r.status_code == 200:\n",
    "#     # from the response object, pass the response text \n",
    "#     # to read_html and get list of tables as list of dataframes\n",
    "    \n",
    "     car_data_tables = pd.read_html(r.text)\n",
    "\n",
    "# # display the first table\n",
    "print(car_data_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e7f06",
   "metadata": {},
   "source": [
    "### From other dataframes\n",
    "\n",
    "#### Method 11:\n",
    "\n",
    "As a copy of another dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a025307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()   # copy into a new dataframe object\n",
    "df_copy = df          # make an alias of the dataframe(not creating \n",
    "                      # a new dataframe, just a pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a new object using .copy() method - new dataframe object created independent of old one\n",
    "a = pd.DataFrame({'year': [2019],'make': [\"Mercedes\"],'model':[\"C-Class\"]})\n",
    "b = a.copy()\n",
    "# change old one\n",
    "a['year'] = 2020\n",
    "# new copy does not reflect the change\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as variable copy - new variable is just an alias to the old one\n",
    "a = pd.DataFrame({'year': [2019],'make': [\"Mercedes\"],'model':[\"C-Class\"]})\n",
    "b = a\n",
    "# change old one\n",
    "a['year'] = 2020\n",
    "# alias reflects the change\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6b733",
   "metadata": {},
   "source": [
    "#### Method 12:\n",
    "\n",
    "Vertical concatenation — one on top of the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [        \n",
    "        {'year': 2018, 'make': \"honda\", 'model':\"civic\"}, \n",
    "        {'year': 2020, 'make': \"hyndai\", 'model':\"nissan\"}, \n",
    "        {'year': 2017, 'make': \"nissan\" ,'model':\"sentra\"}\n",
    "       ]\n",
    "df1 = pd.DataFrame(data1)\n",
    "data2 = [{'year': 2019, 'make': \"bmw\", 'model':\"x5\"}]\n",
    "df2 = pd.DataFrame(data2)\n",
    "# concatenate vertically\n",
    "# NOTE: axis = 'index' is same as axis = 0, and is the default \n",
    "# The two statements below mean the same as the one above\n",
    "df3 = pd.concat([df1,df2], axis = 'index') \n",
    "#OR\n",
    "df3 = pd.concat([df1,df2], axis = 0)\n",
    "# OR\n",
    "df3 = pd.concat([df1,df2])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2deee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1,df2]).reset_index()\n",
    "#OR\n",
    "df3 = pd.concat([df1,df2], ignore_index = True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7db2a",
   "metadata": {},
   "source": [
    "#### Method 13:\n",
    "\n",
    "Horizontal concatenation — append side by side, not joined by any key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b473f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [{'year': 2014, 'make': \"toyota\", 'model':\"corolla\"}, \n",
    "        {'year': 2018, 'make': \"honda\", 'model':\"civic\"}, \n",
    "        {'year': 2020, 'make': \"hyndai\", 'model':\"nissan\"}, \n",
    "        {'year': 2017, 'make': \"nissan\" ,'model':\"sentra\"}\n",
    "       ]\n",
    "df1 = pd.DataFrame(data1)\n",
    "data2 = [{'year': 2019, 'make': \"bmw\", 'model':\"x5\"}]\n",
    "df2 = pd.DataFrame(data2)\n",
    "df3 = pd.concat([df1,df2], axis = 'columns')\n",
    "#OR\n",
    "df3 = pd.concat([df1,df2], axis = 1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9032a6f7",
   "metadata": {},
   "source": [
    "#### Method 14:\n",
    "\n",
    "Horizontal concatenation — equivalent of SQL join.\n",
    "Inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [{'year': 2014, 'make': \"toyota\", 'model':\"corolla\"}, \n",
    "        {'year': 2018, 'make': \"honda\", 'model':\"civic\"}, \n",
    "        {'year': 2020, 'make': \"hyndai\", 'model':\"nissan\"}, \n",
    "        {'year': 2017, 'make': \"nissan\" ,'model':\"sentra\"}\n",
    "       ]\n",
    "df1 = pd.DataFrame(data1)\n",
    "data2 = [{'make': 'honda', 'Monthly Sales': 114117}, \n",
    "        {'make': 'toyota', 'Monthly Sales': 172370}, \n",
    "        {'make': 'hyndai', 'Monthly Sales': 54790}\n",
    "       ]\n",
    "df2 = pd.DataFrame(data2)\n",
    "# inner join on 'make'\n",
    "# default is inner join\n",
    "df3 = pd.merge(df1,df2,how = 'inner',on = ['make'])\n",
    "df3 = pd.merge(df1,df2,on = ['make'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "Left join\n",
    "\n",
    "# for a left join , use how = 'left'\n",
    "df3 = pd.merge(df1,df2,how = 'left',on = ['make'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df3482",
   "metadata": {},
   "source": [
    "#### Method 15:\n",
    "\n",
    "As a transpose of another dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transpose a dataframe - use .T method\n",
    "df4 = df3.T\n",
    "# To rename columns to anything else after the transpose\n",
    "df4.columns = (['column1','column2','column3','column4'])\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f0705",
   "metadata": {},
   "source": [
    "#### Method 16:\n",
    "\n",
    "Conversion to one-hot columns (used for modeling with learning algorithms) using pandas get_dummies function.\n",
    "\n",
    "One-Hot is basically a conversion of a column value into a set of derived columns like Binary Representation Any one of the one-hot column set is 1 and rest is 0.\n",
    "\n",
    "If we know that a car has body types = SEDAN, SUV, VAN, TRUCK, then a Toyota corolla with body = ‘SEDAN’ will become one-hot encoded to\n",
    "\n",
    "    body_SEDAN   body_SUV    body_VAN   body_TRUCK\n",
    "    1             0               0         0\n",
    "\n",
    "\n",
    "Each one hot column is basically of the format \n",
    "\n",
    "    <original_column_name>_<possible_value>\n",
    "\n",
    "#### Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6108051",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [{ 'make': \"toyota\", 'model':\"corolla\", 'body':\"sedan\"}, \n",
    "        {'make': \"honda\", 'model':\"crv\", 'body':\"suv\"}, \n",
    "        {'make': \"dodge\", 'model':\"caravan\", 'body':\"van\"}, \n",
    "        {'make': \"ford\" ,'model':\"f150\", 'body':\"truck\"}\n",
    "       ]\n",
    "df1 = pd.DataFrame(data1) \n",
    "\n",
    "df2 = pd.get_dummies(df1,columns = ['body'])\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
